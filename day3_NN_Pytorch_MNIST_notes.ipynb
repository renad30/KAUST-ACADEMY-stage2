{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renad30/KAUST-ACADEMY-stage2/blob/main/day3_NN_Pytorch_MNIST_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFs5q8XAox82"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKSL__IwozZs"
      },
      "outputs": [],
      "source": [
        "# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n",
        "\n",
        "%pip install torch\n",
        "%pip install matplotlib\n",
        "%pip install torchvision\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xziZ2Kj1pZrq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import MNIST # the dataset is fetched from MINSIT\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tH9YmdSAW7i"
      },
      "source": [
        "#Contents:\n",
        "\n",
        "1. Implementation of 1-2 layer NN fin pytorch which classifies MNIST dataset\n",
        "\n",
        "About MNIST:\n",
        "\n",
        "the dataset consists of images of 28x28 size. The image each contains a handwritten digit from 0 to 9. Our model needs to take this image and classify it to the correct digit.\n",
        "\n",
        "\n",
        "You need to know:\n",
        "\n",
        "1. **pytorch** (for impelementation)\n",
        "2. a little bit of **matplotlib** (for visualization)\n",
        "\n",
        "\n",
        "Good to have knowledge of:\n",
        "\n",
        "1. torch dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZTqeY0V6pV3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922d78b0-72a6-4b52-d320-462b4b8ed978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 444kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.20MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.15MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# MNIST function fetches the MNIST dataset. Without any transform param, the returned object is a Pillow image but we want to convert it to numerical form\n",
        "# that is to say, a numpy array/torch tensor\n",
        "\n",
        "# to_tensor is used to avoid errors when creating data loader later. we'll convert them to numpy arrays when the time comes\n",
        "#train_data = MNIST(??)\n",
        "#test_data  = MNIST(??)\n",
        "\n",
        "train_data = MNIST(root='./datasets', train=True, download=True, transform=to_tensor)\n",
        "test_data  = MNIST(root='./datasets', train=False, download=True, transform=to_tensor)\n",
        "\n",
        "#clear_output()\n",
        "\n",
        "#train_data=[\"data\"][0].shape-> error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note: check the dataset \" important\""
      ],
      "metadata": {
        "id": "Hr2q6E-xfQs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (train_data.data.shape)\n",
        "print (train_data.targets.shape)\n",
        "print (\"number of classes: \", len(train_data.classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx6HwBc3fQZS",
        "outputId": "d975af14-ae11-4b95-e22f-dd69df899ccc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n",
            "number of classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note: it didnt print the color channel so its a grey scale"
      ],
      "metadata": {
        "id": "NDQvqHR-f-TT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PWmnHXbSr9Al"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Dataloaders are used to easily create batches of data so we can perform batch gradient descent for faster learning\n",
        "#train_loader = DataLoader(??, batch_size=batch_size)\n",
        "#test_loader = DataLoader(??, batch_size=batch_size)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size , shuffle= True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aQrW8JC0HBo"
      },
      "source": [
        "## Models\n",
        "\n",
        "let's create the architecture of our models\n",
        "\n",
        "Instead of sigmoid activation, we'll use softmax activation\n",
        "\n",
        "The difference is:\n",
        "- sigmoid brings each value in the range 0-1\n",
        "- softmax takes a vector and changes the value into probabilities: i.e the sum of those values = 1. The highest value in the original vector retains the highest value in softmax output\n",
        "\n",
        "Here's the formula for softmax:\n",
        "\n",
        "$$\n",
        "\\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note : here we defined 2 models"
      ],
      "metadata": {
        "id": "vF6gIWyPXr8g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CXfUV5ZLzGKa"
      },
      "outputs": [],
      "source": [
        "class NN1Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, num_inp, num_out):\n",
        "\n",
        "    super(NN1Layer, self).__init__()\n",
        "\n",
        "    #self.layer_1 = nn.Linear(??, ??)\n",
        "    self.layer_1 = nn.Linear(num_inp, num_out)\n",
        "    #self.softmax = ??\n",
        "    self.softmax =nn.softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    z = self.layer_1(x)\n",
        "    a = self.softmax(z)\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "class NN2Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, num_inp, num_hidden, num_out):\n",
        "\n",
        "    super(NN2Layer, self).__init__()\n",
        "\n",
        "    #self.layer_1 = nn.Linear(??, ??) #my note: ->  (num_inp, num_hidden)\n",
        "    self.layer_1 = nn.Linear (num_inp, num_hidden)\n",
        "    self.layer_2 = nn.Linear(num_hidden, num_out)\n",
        "\n",
        "    self.hidden_activation = nn.ReLU()  # We can change the hidden activation (activation in between layer 1 and 2) here\n",
        "    self.softmax = nn.Softmax(dim=1)  # dim 0 is normally batch size, we don't want to apply softmax across batch size\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    z1 = self.layer_1(x)\n",
        "    a1 = self.hidden_activation(z1)\n",
        "\n",
        "    z2 = self.layer_2(a1)\n",
        "    a2 = self.softmax(z2)\n",
        "\n",
        "    return a2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EX codes i added"
      ],
      "metadata": {
        "id": "63dB8J-oc2dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 layers:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NN3Layer(nn.Module):\n",
        "    def __init__(self, num_inp, num_hidden1, num_hidden2, num_out):\n",
        "        super(NN3Layer, self).__init__()\n",
        "\n",
        "        # Define layers\n",
        "        self.layer_1 = nn.Linear(num_inp, num_hidden1)  # First hidden layer\n",
        "        self.layer_2 = nn.Linear(num_hidden1, num_hidden2)  # Second hidden layer\n",
        "        self.layer_3 = nn.Linear(num_hidden2, num_out)  # Output layer\n",
        "\n",
        "        # Activation functions\n",
        "        self.hidden_activation1 = nn.ReLU()  # Activation for the first hidden layer\n",
        "        self.hidden_activation2 = nn.ReLU()  # Activation for the second hidden layer\n",
        "        self.softmax = nn.Softmax(dim=1)  # Softmax for output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        z1 = self.layer_1(x)\n",
        "        a1 = self.hidden_activation1(z1)\n",
        "\n",
        "        z2 = self.layer_2(a1)\n",
        "        a2 = self.hidden_activation2(z2)\n",
        "\n",
        "        z3 = self.layer_3(a2)\n",
        "        a3 = self.softmax(z3)\n",
        "\n",
        "        return a3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "hzfWCztSc2G3",
        "outputId": "aed7c6b1-50f0-4899-a1d6-72b6321dd335"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-4fce8f2e4088>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4fce8f2e4088>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    3 layers:\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u_e7ldrtHh1"
      },
      "source": [
        "## The main training loop, with batch gradient descent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhSQZRw36s0k"
      },
      "source": [
        "Declare model, it's params, optimizers and criterion etc\n",
        "\n",
        "We'll also declare a device here. This will let us use GPU\n",
        "you can see how much difference a GPU makes by changing the device param to cpu and cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCMTZkue74nL",
        "outputId": "9f10e2c8-55d6-4048-a9d8-0d528038acfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 12\n",
        "lr = 1e-4 #my note : leaerning rate= 10^-4 = 0.0001\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # checks if machine supports cuda and if it does, we use that, otherwise cpu\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# model = NN1Layer(28*28, 10)  # 28*28 because that's the input size. 10 because that's the numbber of classes (0-9)\n",
        "model = NN2Layer(28*28, 32, 10)  # The 2 layer one is equivalent to the one we implemented in numpy\n",
        "\n",
        "#optimizer= ??\n",
        "optimizer = Adam(model.parameters(), lr=lr) #my note: for the optimizer i should use the Adam or AdamW \" dont forget to import it\"\n",
        "#criterion = ??\n",
        "criterion = nn.CrossEntropyLoss() # multi-class , my note : for binary-> criterion = nn.BCELoss()\n",
        "\n",
        "model.to(device)  # we need to send all input tensors as well as our model to this device. by default they are on cpu\n",
        "\n",
        "print(f'Using device {device}') # my note: so both the model and the data will be at the same place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r4KeFeG8mF4"
      },
      "source": [
        "Pre-train performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note: here we are just calculating the model accurcy\"val\" without any training"
      ],
      "metadata": {
        "id": "GI9IKby5NoGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-qDqF6f8oIp",
        "outputId": "c007329b-0a26-45d4-a817-eda7d4e40709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss=2.3019142818450926. labelled 1126/10000 correctly (11.26% accuracy)\n",
            "CPU times: user 1.51 s, sys: 61 ms, total: 1.57 s\n",
            "Wall time: 1.88 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model.eval()\n",
        "correctly_labelled = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  val_epoch_weighted_loss = 0\n",
        "\n",
        "  for val_batch_X, val_batch_y in test_loader:\n",
        "\n",
        "    #val_batch_X = val_batch_X.view(??, ??).to(device)\n",
        "    val_batch_X = val_batch_X.view(-1, 28*28).to(device)\n",
        "    val_batch_y = val_batch_y.to(device)\n",
        "\n",
        "    val_batch_y_probs = model(val_batch_X)\n",
        "\n",
        "    #loss = criterion(??, ??)\n",
        "    loss = criterion(val_batch_y_probs, val_batch_y)\n",
        "    val_epoch_weighted_loss += (len(val_batch_y)*loss.item())\n",
        "\n",
        "    val_batch_y_pred = val_batch_y_probs.argmax(dim=1)  # convert probailities to labels by picking the label (index) with the highest prob\n",
        "\n",
        "    correctly_labelled += (val_batch_y_pred == val_batch_y).sum().item()  # item converts tensor to float/int/list\n",
        "\n",
        "val_epoch_loss = val_epoch_weighted_loss/len(test_loader.dataset)\n",
        "val_losses.append(val_epoch_loss)\n",
        "\n",
        "print(f'val_loss={val_epoch_loss}. labelled {correctly_labelled}/{len(test_loader.dataset)} correctly ({correctly_labelled/len(test_loader.dataset)*100}% accuracy)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzBFOA48Fb7"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy0ChPzH7_wx",
        "outputId": "74e318e9-b823-4a9f-8728-596b104e6f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, train_loss=1.5498319881439209, val_loss=1.546555842399597. labelled 9267/10000 correctly (92.67% accuracy)\n",
            "Epoch: 1, train_loss=1.5479400236129761, val_loss=1.5458262033462524. labelled 9263/10000 correctly (92.63% accuracy)\n",
            "Epoch: 2, train_loss=1.5462240504582723, val_loss=1.5433577396392821. labelled 9286/10000 correctly (92.86% accuracy)\n",
            "Epoch: 3, train_loss=1.5446096230824788, val_loss=1.542882624053955. labelled 9278/10000 correctly (92.78% accuracy)\n",
            "Epoch: 4, train_loss=1.5431195885340372, val_loss=1.5414981567382813. labelled 9284/10000 correctly (92.84% accuracy)\n",
            "Epoch: 5, train_loss=1.5417282983144125, val_loss=1.5404175924301147. labelled 9290/10000 correctly (92.9% accuracy)\n",
            "Epoch: 6, train_loss=1.5404080218633016, val_loss=1.5396028272628783. labelled 9300/10000 correctly (93.0% accuracy)\n",
            "Epoch: 7, train_loss=1.539094907951355, val_loss=1.5385210706710815. labelled 9312/10000 correctly (93.12% accuracy)\n",
            "Epoch: 8, train_loss=1.5379989751815797, val_loss=1.5375162031173706. labelled 9320/10000 correctly (93.2% accuracy)\n",
            "Epoch: 9, train_loss=1.536879523976644, val_loss=1.5366666610717774. labelled 9320/10000 correctly (93.2% accuracy)\n",
            "Epoch: 10, train_loss=1.5357150440216065, val_loss=1.535985417366028. labelled 9331/10000 correctly (93.31% accuracy)\n",
            "Epoch: 11, train_loss=1.5347229327519736, val_loss=1.5350125169754028. labelled 9342/10000 correctly (93.42% accuracy)\n",
            "Training complete on device cuda. Change device variable and run again to see the difference.\n",
            "CPU times: user 1min 42s, sys: 517 ms, total: 1min 43s\n",
            "Wall time: 1min 44s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch_no in range(num_epochs): #my note: epoch\n",
        "\n",
        "  model.train()  # convert to train model. This turns out train-specific layers in the model (if you dont know about them, an example of them is dropout. more on this later)\n",
        "\n",
        "  epoch_weighted_loss = 0\n",
        "                                                                                                                        #my note: for grey scale: .view(-1, 28*28).to(device)\n",
        "                                                                                                                        #         for color scale: .view(-1, 3*28*28).to(device)\n",
        "  for batch_X, batch_y in train_loader:# my note: step                                                                  # .view = reshape in pandas\n",
        "                                                                                                                        # device is cuda\n",
        "\n",
        "    batch_X = batch_X.view(-1, 28*28).to(device)  # convert to [N, 28*28] shape where N is batch_size\n",
        "    batch_y = batch_y.to(device)\n",
        "\n",
        "    batch_y_probs = model(batch_X)  # outputs [N, 10] where each [:, 10] is probabilities for class (0-9) # mu note: here er are trsining the modle \" forward pass\"\n",
        "\n",
        "    loss = criterion(batch_y_probs,batch_y) # my note: here er are calculating the loss \" backward pass\"\n",
        "\n",
        "    optimizer.zero_grad()  # need to clear out gradients from previous batch\n",
        "    loss.backward()  # calculate new gradients\n",
        "    optimizer.step()  # update weights\n",
        "\n",
        "    epoch_weighted_loss += (len(batch_y)*loss.item()) # my note: here we are summing the loss\n",
        "\n",
        "  epoch_loss = epoch_weighted_loss/len(train_loader.dataset)\n",
        "  train_losses.append(epoch_loss)    # add loss for tracking. we'll visualize the loss trajectory later\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # validation time, my note : same as the train loop but without updating the weghits\n",
        "\n",
        "  model.eval()  # take model to evaluation mode. turn off train-only layers\n",
        "  correctly_labelled = 0\n",
        "\n",
        "  with torch.no_grad():  # this makes our model to NOT track gradients\n",
        "\n",
        "    val_epoch_weighted_loss = 0\n",
        "\n",
        "    for val_batch_X, val_batch_y in test_loader:\n",
        "\n",
        "      val_batch_X = val_batch_X.view(-1, 28*28).to(device)\n",
        "      val_batch_y = val_batch_y.to(device)\n",
        "\n",
        "      #val_batch_y_probs = model(??)\n",
        "      val_batch_y_probs = model(val_batch_X)\n",
        "\n",
        "      #loss = criterion(??, ??)\n",
        "      loss = criterion(val_batch_y_probs, val_batch_y)\n",
        "\n",
        "      val_epoch_weighted_loss += (len(val_batch_y)*loss.item())\n",
        "\n",
        "      val_batch_y_pred = val_batch_y_probs.argmax(dim=1)  # convert probailities to labels by picking the label (index) with the highest prob\n",
        "\n",
        "      correctly_labelled += (val_batch_y_pred == val_batch_y).sum().item()  # item converts tensor to float/int/list\n",
        "\n",
        "  #val_epoch_loss = val_epoch_weighted_loss/len(??)\n",
        "\n",
        "  val_epoch_loss = val_epoch_weighted_loss/len(test_loader.dataset)\n",
        "  val_losses.append(val_epoch_loss)\n",
        "\n",
        "  print(f'Epoch: {epoch_no}, train_loss={epoch_loss}, val_loss={val_epoch_loss}. labelled {correctly_labelled}/{len(test_loader.dataset)} correctly ({correctly_labelled/len(test_loader.dataset)*100}% accuracy)')\n",
        "\n",
        "print(f'Training complete on device {device}. Change device variable and run again to see the difference.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvNZwZsd_4Nf"
      },
      "source": [
        "Loss trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Jtaq-nooqSj9",
        "outputId": "4c7ef2f1-7f62-411b-e89c-5c8c502d610e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='val loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (Cross Entropy)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Jf5i7IAswc"
      },
      "source": [
        "visualizing shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOaxXyMg-ahW",
        "outputId": "ab4e6b48-9e0d-4756-e0f9-aa77d5323253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 10])\n",
            "torch.Size([16])\n",
            "\n",
            "\n",
            "To verify softmax converts inputs into probabilities (sum of which is 1), let's sum those probabilities and see if we get 1's: \n",
            "\n",
            "val_batch_y_probs.sum(1)=tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "       device='cuda:0')\n",
            "\n",
            "val_batch_y_probs.sum(1).shape=torch.Size([16])\n",
            "\n",
            "\n",
            "Lets see argmax in action\n",
            "Here's one of the input to argmax\n",
            "\n",
            "tensor([2.9502e-10, 1.7637e-25, 1.3249e-08, 6.6339e-19, 1.8074e-11, 1.7071e-11,\n",
            "        1.0000e+00, 3.1008e-20, 1.3269e-13, 2.3319e-16])\n",
            "\n",
            "\n",
            "Here's its output\n",
            "tensor(6)\n"
          ]
        }
      ],
      "source": [
        "print(val_batch_X.shape, val_batch_y.shape)  # 784 is 28*28\n",
        "print(val_batch_y_probs.shape)  # inference from model\n",
        "print(val_batch_y_pred.shape)  # probabilities converted\n",
        "\n",
        "print(\"\\n\\nTo verify softmax converts inputs into probabilities (sum of which is 1), let's sum those probabilities and see if we get 1's: \\n\")\n",
        "print(f'{val_batch_y_probs.sum(1)=}')\n",
        "\n",
        "print(f'\\n{val_batch_y_probs.sum(1).shape=}')\n",
        "\n",
        "print('\\n\\nLets see argmax in action')\n",
        "print(\"Here's one of the input to argmax\\n\")\n",
        "test_idx = 15\n",
        "print(val_batch_y_probs[test_idx].cpu())  # .cpu() brings a tensor back to cpu device from any other it might be on (like cuda)\n",
        "print(\"\\n\\nHere's its output\")\n",
        "print(val_batch_y_pred[test_idx].cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iw2G2akA5lB"
      },
      "source": [
        "Saving and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Hi61n3DJAtvp"
      },
      "outputs": [],
      "source": [
        "# you can load save the model's state dict like this\n",
        "torch.save(model.state_dict(), 'MNIST_classifier.pt')  # take a look at the storage section if you're on colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC84w0WpBE2Q",
        "outputId": "fdc5ffd1-2525-4ec0-c466-6b7836abfbfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before loading model\n",
            "1/16 correct\n",
            "After loading model\n",
            "16/16 correct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-3d8b10a6368e>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load('MNIST_classifier.pt'))\n"
          ]
        }
      ],
      "source": [
        "loaded_model = NN2Layer(28*28, 32, 10)  # just an empty model.\n",
        "loaded_model.eval().to(device)\n",
        "\n",
        "print('Before loading model')\n",
        "\n",
        "with torch.no_grad():\n",
        "  probs = loaded_model(val_batch_X)\n",
        "  preds = probs.argmax(dim=1)\n",
        "\n",
        "  print(f'{(preds==val_batch_y).sum()}/{len(preds)} correct')\n",
        "\n",
        "\n",
        "print('After loading model')\n",
        "loaded_model.load_state_dict(torch.load('MNIST_classifier.pt'))\n",
        "\n",
        "with torch.no_grad():\n",
        "  probs = loaded_model(val_batch_X)\n",
        "  preds = probs.argmax(dim=1)\n",
        "\n",
        "  print(f'{(preds==val_batch_y).sum()}/{len(preds)} correct')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTWzqt7SCQaz"
      },
      "source": [
        "END."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n4cITtHB6Xa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}